{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Словарь исправленных токенов"
      ],
      "metadata": {
        "id": "IPSJ8x84YddF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Итак, теперь наша задача — объединить функции, которые у нас уже есть, чтобы начать исправлять опечатки в тексте.\n",
        "\n",
        "Позже, в интерфейсе нашего приложения, которое мы пишем, нам понадобится вывести текст, который уже будет содержать слова с исправленными опечатками и пометки о том, какие именно слова были исправлены.\n",
        "\n",
        "Чтобы вывести этот текст, нам надо составить **словарь** специального вида. Ключом будет токен из входного текста, а значением к каждому токену — вложенный словарь.\n",
        "\n",
        "### Вложенный словарь\n",
        "\n",
        "Во-первых, мы ленивые, поэтому хотим делать как можно меньше работы, а значит, мы должны отсеять слова, которые не будем исправлять. Это части речи, которые функция `get_tokens_dict()` отмечает как `True`, то есть части речи, которые трудно или нельзя проанализировать на факт опечатки: служебные слова, аббревиатуры, спецсимволы и имена собственные. В нашем вложенном словаре за этот параметр будет отвечать ключ `'special'`. Если его значение `True`, это значит, что мы не работаем с токеном далее и выводим его таким, каким нашли, без исправлений и пометок. В случае `False` продолжаем работу.\n",
        "\n",
        "Во-вторых, мы хотим запоминать, нашли ли мы в слове опечатку. За это будет отвечать ключ `'corrected'`, так же со значениями `True` и `False`. Если слово `'special': True`, логично тут сразу говорить, что опечаток мы в нем не нашли (потому что не искали). Если мы отметили слово как исправленное, то позже в тексте мы будем выводить его с соответсвующей пометкой.\n",
        "\n",
        "В-третьих, мы должны знать, какой токен в итоге надо показать пользователю. Его мы будем хранить под ключом `'corrected_word'`.\n",
        "\n",
        "Пример:\n",
        "```\n",
        "{'in': {\n",
        "  'special': True,\n",
        "  'corrected': False,\n",
        "  'corrected_word': 'in'},\n",
        "'letter': {\n",
        "  'special': False,\n",
        "  'corrected': False,\n",
        "  'corrected_word': 'letter'},\n",
        "'generql': {\n",
        "  'special': False,\n",
        "  'corrected': True,\n",
        "  'corrected_word': 'general'},\n",
        "}\n",
        "```\n",
        "\n",
        "Собственно, на данном этапе это все, что мы должны получить.\n",
        "\n"
      ],
      "metadata": {
        "id": "NcxuBibRYfKN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Работа с JSON"
      ],
      "metadata": {
        "id": "dSINUC7_y3-i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Понятно, что мы будем исправлять опечатки сверяясь с каким-то источником, на который будем полагаться как на образец написания слов. В нашем случае это будет уже готовый для тебя набор данных. Но хранится он в отдельном файле и его надо как-то открыть...\n",
        "\n",
        "А хранится он в файле типа JSON, то есть JavaScript Object Notation. Это файлы, которые позволяют сохранять объекты разных типов. Python умеет работать с этими файлами с помощью встроенной библиотеки json.\n",
        "\n",
        "```\n",
        "import json\n",
        "```"
      ],
      "metadata": {
        "id": "GQ69Aa7vaeS0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Открыть какой-либо файл позволяет служебное слово `with` и функция `open()`.\n",
        "\n",
        "Например, я хочу открыть произвольный текстовый файл с названием \"1\" и расширением txt, а обращаться буду к нему как к переменной file_1. Тогда:\n",
        "\n",
        "```\n",
        "with open('1.txt') as file_1:\n",
        "  # после одного отступа осуществляется работа с файлом\n",
        "\n",
        "# когда мы выходим из with, файл закрывается\n",
        "```\n",
        "\n",
        "Чтобы загрузить содержание файла в переменную, пользуются функцией load()\n",
        "\n",
        "```\n",
        "content = json.load()\n",
        "```\n",
        "\n",
        "В нашем файле-образце будет лежать только один массив (это соответствует питоновскому списку), поэтому в переменную запишется только один список, состоящий из слов."
      ],
      "metadata": {
        "id": "wmqEqdseecvN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqgdgFt-YWFW"
      },
      "outputs": [],
      "source": [
        "# Открой файл sample.json и запиши его содержание в переменную sample_list:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Совмещение написанных ранее функций"
      ],
      "metadata": {
        "id": "zRFVmeuEgNEd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Инициализация `dict_of_corrections`"
      ],
      "metadata": {
        "id": "uPYOAZ11yp-n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь мы хотим пройти по тексту, который предложен пользователем, и создать словарь, который описали выше. Пусть он называется `dict_of_corrections`. Инициализируем его (в готовом для тебя виде и поясним код).\n",
        "\n"
      ],
      "metadata": {
        "id": "xzVfMQT5gNTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_tokens_dict = {\n",
        "    'word': False,\n",
        "    'USA': True,\n",
        "    'applicqtion': False\n",
        "}\n",
        "\n",
        "dict_of_corrections = dict()\n",
        "for key, value in text_tokens_dict.items():\n",
        "    dict_of_corrections[key] = {\n",
        "        'special': bool(), 'corrected': bool(), 'corrected_word': str()\n",
        "    }"
      ],
      "metadata": {
        "id": "pq8ZmCgEhUVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Перед началом работы мы предлагаем нашей функции какой-то небольшой словарь токенов `text_tokens_dict` (предположим, что он является результатом разбития на токены), содержанием которого мы заполним `dict_of_corrections`.\n",
        "\n",
        "Теперь мы сообщаем, что переменная `dict_of_corrections` по типу является словарем.\n",
        "\n",
        "Мы пополняем словарь токенами из исходного текста. Значит, мы обращаемся к функции `get_tokens_dict()`, которая нам возвращает словарь со значениями, является ли токен исправимым, и с помощью цикла пробегаемся по его значениям. Но как корректно пробегаться по словарю с помощью цикла? Тут очень полезен метод словаря `.items()`. Он превращает словарь в список из неизменяемых пар ключ-значение.\n",
        "\n",
        "Чтобы с помощью цикла пробегаться по такому списку пар, мы можем пользоваться двумя переменными внутри оператора for. Смотри пример:"
      ],
      "metadata": {
        "id": "WJyqZSWGhYkl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example = [(1, 2), (3, 4), (5, 6)]\n",
        "\n",
        "for key, value in example:\n",
        "    print(key)\n",
        "    print(value)"
      ],
      "metadata": {
        "id": "clzHgpRAjaEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# сделай тоже самое, но уже со словарем, с помощью .items():\n",
        "example = {1: 2, 3: 4, 5: 6}"
      ],
      "metadata": {
        "id": "CNsFl7p1kGak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Точно так же мы поступим с нашим словарем. Мы хотим пройти по его значениями. Сперва мы будем добавлять соответствующий ключ в наш `dict_of_corrections`. Чтобы добавить или обновить значение в словаре `dict1` по ключу `key`, надо просто указать индекс: `dict1[key]`.\n",
        "\n",
        "```\n",
        "dict_of_corrections[token] = dict()\n",
        "```\n",
        "Но пока вложенных словарей у нас нет, мы хотим их заполнить тремя параметрами, озвученными нами в первом разделе (`special`, `corrected`, `corrected_word`). Мы делаем это, вставляя заготовку словаря, где указываем типы значений, которые будем хранить в них. `bool()` это булиан, то есть логическое `True` или `False`. `string()` возвращает просто пустую строчку. На этом инициализация закончена!\n",
        "\n"
      ],
      "metadata": {
        "id": "S5_QkP_ujyT8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Заполнение словаря"
      ],
      "metadata": {
        "id": "oliNrzJ-yhBW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Во-первых, если функция `get_tokens_dict()` сопоставила токену значение `True`, то мы сразу знаем, что делать.\n",
        "\n",
        "Заметь, что раз у нас в значении словаря вложен словарь, то чтобы обратиться **к индексу вложенного словаря**, достаточно написать **следующие друг за другом** индексы:"
      ],
      "metadata": {
        "id": "zRVDS4jayhNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if value == True:\n",
        "    dict_of_corrections[key]['special'] = True  # Это функциональный токен?\n",
        "    dict_of_corrections[key]['corrected'] = False\n",
        "    dict_of_corrections[key]['corrected_word'] = key  # Что в итоге мы покажем? изменилось ли что-то?"
      ],
      "metadata": {
        "id": "vMppYcg1lMod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Иной случай придется рассматривать более подробно.\n",
        "\n",
        "```\n",
        "else:\n",
        "    # будем работать тут\n",
        "```\n",
        "\n",
        "Сначала, мы хотим узнать, есть ли в слове вообще опечатка. Если наше слово есть в `sample_list`, это значит, что мы примем его за правильно написанное. Условие вхождения проверяется с помощью служебного слова `in`.\n",
        "\n",
        "Пример:\n",
        "\n"
      ],
      "metadata": {
        "id": "Cj8anI8BmhrF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(1 in [1, 2, 'cat'])  # Есть ли элемент в списке?\n",
        "\n",
        "print('me' in 'America')  # Есть ли подстрока в строке?\n",
        "\n",
        "print('any money' in ['my purse', 'my life', 'my future'])  # Just for fun"
      ],
      "metadata": {
        "id": "-EcBRzA2nKN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Если мы начнем проверять слово `'House'` на вхождение в наш массив, оно не найдется! А все потому, что слова `'House'` и `'house'` отличаются начальным символом. Поэтому, когда мы хотим проверить вхождение слова в код, мы должны искать его версию без заглавных букв. Это делается методом .lower():\n",
        "\n",
        "\n",
        "```\n",
        "'HoUsE'.lower() >>> 'house'\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "q4wVDlO53YPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверяем является ли слово специальным\n",
        "if value == True:\n",
        "    dict_of_corrections[key]['special'] = True\n",
        "    dict_of_corrections[key]['corrected'] = False\n",
        "    dict_of_corrections[key]['corrected_word'] = key\n",
        "else:\n",
        "    # Проверяем, есть ли слово в массиве образцовых слов.\n",
        "    # Напиши свой код ниже\n",
        "    # Воспользуйся методом .lower()\n",
        "\n"
      ],
      "metadata": {
        "id": "WzdWryzQZRLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Остался один случай (опять `else:`). Наше слово не содержится в списке-образце. Значит, мы хотим его исправить. Чтобы это сделать, надо найти слово, которое по расстоянию Левенштейна ближе всего к нему.\n",
        "\n",
        "Таких слов может оказаться несколько, но наш список-образец организован удобно — самые частые слова в нем ближе к началу, более редкие — в конце. Мы знаем еще одну вещь: если расстояние до какого-то слова оказалось ровно 1, **меньше уже не будет**."
      ],
      "metadata": {
        "id": "fhAYzZzun43P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "То есть, в этом случае мы начинаем с помощью цикла проходить по значениям из sample_list и строить расстояния между ними и нашим токеном key. На каждом шаге цикла мы должны применить функцию `levenstein(str_1, str_2)`, и запоминать, до какого слова расстояние наименьшее и каково оно в точности.\n",
        "\n",
        "Пусть мы будем записывать такое слово в переменную `correct_word`, а расстояние до него в `distance`. Только если расстояние оказывается **строго меньше**, тогда мы обновляем эти значения. Строго меньше потому, что каждое следующее слово в списке более редкое, а значит, меньше вероятность, что именно оно имелось в виду, поэтому **среди слов с одинаковым расстоянием** следует выбрать то, которое **раньше**.\n",
        "\n"
      ],
      "metadata": {
        "id": "IHhNwO1DspKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Мы начнем работу ВНЕ ЦИКЛА, чтобы записать какое-то начальное значение distance, с которым можно будет сравнивать далее:\n",
        "distance = levenstein(key.lower(), sample_list[0])\n",
        "correct_word = sample_list[0]\n",
        "\n",
        "# Определи для токена key то слово из sample_list, до которого расстояние наименьшее:"
      ],
      "metadata": {
        "id": "vJ66zRfWzzSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Если мы нашли слово с расстоянием 1, идти дальше уже нет смысла. Значит, цикл можно прервать. Это делается служебным словом `break`. Пример:"
      ],
      "metadata": {
        "id": "ksJYO4AvvZHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list1 = [1, 2, 3, 4, 5, 6]\n",
        "\n",
        "for number in list1:\n",
        "  print(number)\n",
        "  if number == 3:\n",
        "    break"
      ],
      "metadata": {
        "id": "AhgJ2CcHvYmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distance = levenstein(key, sample_list[0])\n",
        "correct_word = sample_list[0]\n",
        "# Определи для токена key слово из sample_list, до которого расстояние наименьшее\n",
        "\n",
        "\n",
        "# Остановись, если нашел расстояние ровно 1:"
      ],
      "metadata": {
        "id": "g3LBD6blz_x_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "В итоге, в случае, если мы корректировали слово, во вложенный `dict_of_corrections[key]` мы хотим сообщить, что **мы исправили слово**, и записать, **на что** мы его исправили."
      ],
      "metadata": {
        "id": "zOxFYWmewLAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distance = levenstein(key, sample_list[0])\n",
        "correct_word = sample_list[0]\n",
        "# Определи для токена key слово из sample_list, до которого расстояние наименьшее\n",
        "# Остановись, если нашел расстояние ровно 1\n",
        "\n",
        "# Когда мы закончили работу в цикле, заполни словарь:"
      ],
      "metadata": {
        "id": "NTSfJvFT0RY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Осталось объединить всё в функцию build_dict(). Перед этим нужно подготовить функции для создания массива образцовых слов и словаря токенов из текста, а также для рассчёта расстояния Левенштейна. Первое тебе нужно сделать самому, остальное мы подготовили и осталось лишь запустить:"
      ],
      "metadata": {
        "id": "osyyOD2edUrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json  # Импортируем библиотеку для открытия массива с образцовыми словами\n",
        "\n",
        "\n",
        "def get_words_massive():\n",
        "  # Открой здесь json массив с образцовыми словами\n",
        "  # и присвой его переменной words_massive\n",
        "\n",
        "  # Возвращаем массив образцовых слов\n",
        "  return words_massive"
      ],
      "metadata": {
        "id": "MVFlstg-doUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Запусти эту ячейку, чтобы создать функцию по получению словаря токенов.\n",
        "# Функция является просто образцом вывода на основе предложенного текста\n",
        "def get_tokens_dict(text):\n",
        "    tokens_dict = {\n",
        "        '\\n': True,\n",
        "        'Twin': True,\n",
        "        'Peaks': True,\n",
        "        'is': False,\n",
        "        'an': False,\n",
        "        'Amercan': False,\n",
        "        'mystery': False,\n",
        "        'sirial': False,\n",
        "        'drama': False,\n",
        "        'televizion': False,\n",
        "        'series': False,\n",
        "        'created': False,\n",
        "        'by': True,\n",
        "        'Mark': True,\n",
        "        'Frost': True,\n",
        "        'and': True,\n",
        "        'David': True,\n",
        "        'Lynch': True,\n",
        "        '.': True,\n",
        "        'It': False,\n",
        "        'premeired': False,\n",
        "        'on': True,\n",
        "        'ABC': True,\n",
        "        'April': True,\n",
        "        '8': False,\n",
        "        ',': True,\n",
        "        '1990': False,\n",
        "        'ran': False,\n",
        "        'for': True,\n",
        "        'twoo': False,\n",
        "        'seasons': False,\n",
        "        'until': True,\n",
        "        'its': False,\n",
        "        'cancellation': False,\n",
        "        'in': True,\n",
        "        '1991': False,\n",
        "        'The': False,\n",
        "        'show': False,\n",
        "        'returned': False,\n",
        "        '2017': False,\n",
        "        'a': False,\n",
        "        'third': False,\n",
        "        'season': False,\n",
        "        'Showtime': True\n",
        "    }\n",
        "\n",
        "    return tokens_dict"
      ],
      "metadata": {
        "id": "K-0R_J7ydqZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Запусти эту ячейку, чтобы создать функцию по получению расстояния Левенштейна\n",
        "def levenstein(str_1, str_2):\n",
        "    n = len(str_1)\n",
        "    m = len(str_2)\n",
        "    current_row = []\n",
        "    for k in range(m+1):\n",
        "        current_row += [k]\n",
        "    for i in range(1, n+1):\n",
        "        previous_row = current_row\n",
        "        current_row = [i] + [0] * m\n",
        "        for j in range(1, m+1):\n",
        "            left = current_row[j-1] + 1\n",
        "            up = previous_row[j] + 1\n",
        "            left_up = previous_row[j-1]\n",
        "            if str_1[i-1] != str_2[j-1]:\n",
        "                left_up += 1\n",
        "        current_row[j] = min(up, left, left_up)\n",
        "    return current_row[-1]"
      ],
      "metadata": {
        "id": "P8zCyIiLf6Hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Наконец, заполни функцию `build_dict(text)`, следуя инструкции ниже:\n",
        "\n",
        "1.   Открыть json файл и записать его содержимое в `sample_list`\n",
        "2.   Инициализировать словарь `dict_of_corrections`\n",
        "3.   Применить на тексте `text` функцию `get_tokens_dict()`\n",
        "4.   Пройти по парам `key` `value` из ее результа, пользуясь `.items()`\n",
        "5.   Проверить, токен `key` попадает в категорию `'special'`\n",
        "6.   Если нет, то проверить, он входит в список `sample_list`\n",
        "7.   Если опять нет, то исправить его и запомнить, на что мы его исправили\n",
        "8.   Вернуть заполненный словарь `dict_of_corrections`"
      ],
      "metadata": {
        "id": "ZF3VVjrSd9CZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dict(text):\n",
        "    words_massive = get_words_massive()  # Получим массив образцовых слов\n",
        "    text_tokens_dict = get_tokens_dict(text)  # Получим словарь токенов из текста\n",
        "\n",
        "    # Иницилизируем словарь, который заполним далее:\n",
        "\n",
        "\n",
        "    # Напиши код, который заполнит словарь dict_of_corrections:\n",
        "\n",
        "\n",
        "    # Верни этот словарь\n",
        "    return dict_of_corrections\n"
      ],
      "metadata": {
        "id": "n4cCSymxeVRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Запусти эту ячейку, чтобы проверить, всё ли работает\n",
        "text = \"\"\"\n",
        "Twin Peaks is an American mystery sirial drama televizion series\n",
        "created by Mark Frost and David Lynch. It premeired on ABC on April 8, 1990,\n",
        "and ran for twoo seasons until its cancellation in 1991. The show returned\n",
        "in 2017 for a third season on Showtime.\n",
        "\"\"\"\n",
        "\n",
        "build_dict(text)"
      ],
      "metadata": {
        "id": "XrCj9XGeeqKF"
      },
      "execution_count": 1,
      "outputs": []
    }
  ]
}