{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Создание массива слов\n",
        "Для того, чтобы находить и исправлять опечатки с помощью расстояния Левенштейна, сперва необходимо создать массив слов, чтобы мы могли найти правильно написанный вариант слова, в котором допустили опечатку.\n",
        "\n",
        "Для этого мы извлёчем все слова из корпуса. Корпус это массив языковых данных, например письменных текстов, аудиозаписей и так далее. Корпуса представлены в электронном виде для решения разных задач. Например, для решения нашей задачи."
      ],
      "metadata": {
        "id": "C7LtQCKSRJcm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Загрузка корпуса\n",
        "Мы воспользуемся одним из немногих доступных корпусов английского языка — Brown Corpus. Для начала необходимо добавить корпус в google colab. Следуй инструкции:\n",
        "1. Открываем files google colab (папка в панель слева).\n",
        "2. Нажимаем левой кнопкой мыши по папке с названием \"...\".\n",
        "3. Нажимаем \"новая папка\"/\"new folder\".\n",
        "4. В качестве названия указываем Brown.\n",
        "5. Кликаем левой кнопкой мыши по папке Brown.\n",
        "6. Нажимаем \"загрузить\"/\"upload\".\n",
        "7. Находим корневую папку проекта.\n",
        "8. Открываем в корневой папке проекта папку Brown.\n",
        "9. Выделяем все файлы комбинацией клавиш \"ctrl + A\".\n",
        "10. Нажимаем \"открыть\"/\"open\".\n",
        "\n",
        "После того, как все файлы прогрузятся (около минуты) перейдём к следующей задаче."
      ],
      "metadata": {
        "id": "ZUxbkBq6S4hd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Обработка корпуса\n",
        "После того, как мы загрузили корпус, необходимо представить все эти текстовые файлы в удобном для нас формате. Проще всего будет воспользоваться функционалом библиотеки corpus_toolkit. Запусти код ниже, чтобы установить всё необходимое:"
      ],
      "metadata": {
        "id": "2yF_6zK_XBYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install corpus-toolkit  # Устанавливаем библиотеку в google colab\n",
        "\n",
        "from corpus_toolkit import corpus_tools as ct  # Импортируем библиотеку\n",
        "import spacy  # Импортируем вспомогательную библиотеку"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ddHgYhvYVJ6",
        "outputId": "1b1a4a3a-0615-4d6e-89a8-0010b85577e7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: corpus-toolkit in /usr/local/lib/python3.10/dist-packages (0.32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Эта библиотека создана для создания так называемых словарей частотностей. Это такие пары ключ-значение, где ключ это слово, а значение количество появлений в корпусе. Мы создадим словарь частотности, а затем вытащим из него все ключи, воспользовавшись кодом из [документации](https://github.com/kristopherkyle/corpus_toolkit)"
      ],
      "metadata": {
        "id": "U9T6lfPkYJCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "brown_corp = ct.ldcorpus('Brown')  # Загружаем корпус\n",
        "tok_corp = ct.tokenize(brown_corp)  # Токенизируем корпус\n",
        "brown_freq = ct.frequency(tok_corp)  # Создаём словарь частотности"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oh003ASYICG",
        "outputId": "680c5a2c-ea78-47d2-dd26-a484d58610c6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing cb_cb13.txt (1 of 500 files)\n",
            "Processing cf_cf23.txt (2 of 500 files)\n",
            "Processing cc_cc08.txt (3 of 500 files)\n",
            "Processing cg_cg65.txt (4 of 500 files)\n",
            "Processing ck_ck08.txt (5 of 500 files)\n",
            "Processing ca_ca42.txt (6 of 500 files)\n",
            "Processing cg_cg04.txt (7 of 500 files)\n",
            "Processing cn_cn26.txt (8 of 500 files)\n",
            "Processing cf_cf38.txt (9 of 500 files)\n",
            "Processing ck_ck28.txt (10 of 500 files)\n",
            "Processing ce_ce21.txt (11 of 500 files)\n",
            "Processing cb_cb17.txt (12 of 500 files)\n",
            "Processing cl_cl10.txt (13 of 500 files)\n",
            "Processing ce_ce32.txt (14 of 500 files)\n",
            "Processing cg_cg33.txt (15 of 500 files)\n",
            "Processing cj_cj39.txt (16 of 500 files)\n",
            "Processing ca_ca12.txt (17 of 500 files)\n",
            "Processing cn_cn14.txt (18 of 500 files)\n",
            "Processing cj_cj80.txt (19 of 500 files)\n",
            "Processing cj_cj67.txt (20 of 500 files)\n",
            "Processing cm_cm03.txt (21 of 500 files)\n",
            "Processing ck_ck27.txt (22 of 500 files)\n",
            "Processing cd_cd11.txt (23 of 500 files)\n",
            "Processing cl_cl03.txt (24 of 500 files)\n",
            "Processing ce_ce10.txt (25 of 500 files)\n",
            "Processing cr_cr04.txt (26 of 500 files)\n",
            "Processing cg_cg39.txt (27 of 500 files)\n",
            "Processing cf_cf47.txt (28 of 500 files)\n",
            "Processing cj_cj32.txt (29 of 500 files)\n",
            "Processing ca_ca22.txt (30 of 500 files)\n",
            "Processing cg_cg28.txt (31 of 500 files)\n",
            "Processing cf_cf46.txt (32 of 500 files)\n",
            "Processing cg_cg19.txt (33 of 500 files)\n",
            "Processing cf_cf17.txt (34 of 500 files)\n",
            "Processing cg_cg32.txt (35 of 500 files)\n",
            "Processing ch_ch27.txt (36 of 500 files)\n",
            "Processing cj_cj55.txt (37 of 500 files)\n",
            "Processing ck_ck26.txt (38 of 500 files)\n",
            "Processing cj_cj33.txt (39 of 500 files)\n",
            "Processing cg_cg45.txt (40 of 500 files)\n",
            "Processing cj_cj34.txt (41 of 500 files)\n",
            "Processing cg_cg54.txt (42 of 500 files)\n",
            "Processing cg_cg03.txt (43 of 500 files)\n",
            "Processing cg_cg01.txt (44 of 500 files)\n",
            "Processing cj_cj47.txt (45 of 500 files)\n",
            "Processing cn_cn09.txt (46 of 500 files)\n",
            "Processing cf_cf28.txt (47 of 500 files)\n",
            "Processing cf_cf08.txt (48 of 500 files)\n",
            "Processing cn_cn03.txt (49 of 500 files)\n",
            "Processing cn_cn02.txt (50 of 500 files)\n",
            "Processing cp_cp12.txt (51 of 500 files)\n",
            "Processing ce_ce25.txt (52 of 500 files)\n",
            "Processing cj_cj61.txt (53 of 500 files)\n",
            "Processing cd_cd12.txt (54 of 500 files)\n",
            "Processing ch_ch28.txt (55 of 500 files)\n",
            "Processing cj_cj52.txt (56 of 500 files)\n",
            "Processing cg_cg55.txt (57 of 500 files)\n",
            "Processing cn_cn25.txt (58 of 500 files)\n",
            "Processing cf_cf06.txt (59 of 500 files)\n",
            "Processing cj_cj18.txt (60 of 500 files)\n",
            "Processing ch_ch13.txt (61 of 500 files)\n",
            "Processing cf_cf21.txt (62 of 500 files)\n",
            "Processing cb_cb11.txt (63 of 500 files)\n",
            "Processing ce_ce24.txt (64 of 500 files)\n",
            "Processing cr_cr02.txt (65 of 500 files)\n",
            "Processing cf_cf30.txt (66 of 500 files)\n",
            "Processing cn_cn17.txt (67 of 500 files)\n",
            "Processing ch_ch29.txt (68 of 500 files)\n",
            "Processing cp_cp10.txt (69 of 500 files)\n",
            "Processing cg_cg56.txt (70 of 500 files)\n",
            "Processing ck_ck03.txt (71 of 500 files)\n",
            "Processing cg_cg52.txt (72 of 500 files)\n",
            "Processing cg_cg36.txt (73 of 500 files)\n",
            "Processing cp_cp17.txt (74 of 500 files)\n",
            "Processing cp_cp02.txt (75 of 500 files)\n",
            "Processing cj_cj43.txt (76 of 500 files)\n",
            "Processing cb_cb05.txt (77 of 500 files)\n",
            "Processing ch_ch10.txt (78 of 500 files)\n",
            "Processing ca_ca11.txt (79 of 500 files)\n",
            "Processing cp_cp13.txt (80 of 500 files)\n",
            "Processing ch_ch12.txt (81 of 500 files)\n",
            "Processing cg_cg24.txt (82 of 500 files)\n",
            "Processing cc_cc01.txt (83 of 500 files)\n",
            "Processing ca_ca23.txt (84 of 500 files)\n",
            "Processing cn_cn07.txt (85 of 500 files)\n",
            "Processing ce_ce30.txt (86 of 500 files)\n",
            "Processing cg_cg05.txt (87 of 500 files)\n",
            "Processing cg_cg35.txt (88 of 500 files)\n",
            "Processing cf_cf37.txt (89 of 500 files)\n",
            "Processing cg_cg73.txt (90 of 500 files)\n",
            "Processing cj_cj56.txt (91 of 500 files)\n",
            "Processing cb_cb09.txt (92 of 500 files)\n",
            "Processing cj_cj38.txt (93 of 500 files)\n",
            "Processing cf_cf43.txt (94 of 500 files)\n",
            "Processing cf_cf15.txt (95 of 500 files)\n",
            "Processing cd_cd08.txt (96 of 500 files)\n",
            "Processing ce_ce28.txt (97 of 500 files)\n",
            "Processing cr_cr05.txt (98 of 500 files)\n",
            "Processing ca_ca09.txt (99 of 500 files)\n",
            "Processing ca_ca18.txt (100 of 500 files)\n",
            "Processing ca_ca30.txt (101 of 500 files)\n",
            "Processing cj_cj28.txt (102 of 500 files)\n",
            "Processing ce_ce17.txt (103 of 500 files)\n",
            "Processing cg_cg27.txt (104 of 500 files)\n",
            "Processing cp_cp15.txt (105 of 500 files)\n",
            "Processing cj_cj77.txt (106 of 500 files)\n",
            "Processing cj_cj02.txt (107 of 500 files)\n",
            "Processing cj_cj54.txt (108 of 500 files)\n",
            "Processing cj_cj46.txt (109 of 500 files)\n",
            "Processing cd_cd15.txt (110 of 500 files)\n",
            "Processing ch_ch21.txt (111 of 500 files)\n",
            "Processing cb_cb08.txt (112 of 500 files)\n",
            "Processing ce_ce19.txt (113 of 500 files)\n",
            "Processing cc_cc11.txt (114 of 500 files)\n",
            "Processing ca_ca44.txt (115 of 500 files)\n",
            "Processing ca_ca07.txt (116 of 500 files)\n",
            "Processing cj_cj22.txt (117 of 500 files)\n",
            "Processing cj_cj51.txt (118 of 500 files)\n",
            "Processing cj_cj49.txt (119 of 500 files)\n",
            "Processing cp_cp04.txt (120 of 500 files)\n",
            "Processing ck_ck09.txt (121 of 500 files)\n",
            "Processing cf_cf09.txt (122 of 500 files)\n",
            "Processing cb_cb01.txt (123 of 500 files)\n",
            "Processing cj_cj20.txt (124 of 500 files)\n",
            "Processing cf_cf10.txt (125 of 500 files)\n",
            "Processing cg_cg46.txt (126 of 500 files)\n",
            "Processing ce_ce01.txt (127 of 500 files)\n",
            "Processing cf_cf01.txt (128 of 500 files)\n",
            "Processing ca_ca05.txt (129 of 500 files)\n",
            "Processing ce_ce33.txt (130 of 500 files)\n",
            "Processing cg_cg18.txt (131 of 500 files)\n",
            "Processing cb_cb26.txt (132 of 500 files)\n",
            "Processing ca_ca27.txt (133 of 500 files)\n",
            "Processing cj_cj12.txt (134 of 500 files)\n",
            "Processing ce_ce29.txt (135 of 500 files)\n",
            "Processing cc_cc02.txt (136 of 500 files)\n",
            "Processing cg_cg08.txt (137 of 500 files)\n",
            "Processing cg_cg17.txt (138 of 500 files)\n",
            "Processing cp_cp26.txt (139 of 500 files)\n",
            "Processing cf_cf14.txt (140 of 500 files)\n",
            "Processing cj_cj19.txt (141 of 500 files)\n",
            "Processing cn_cn12.txt (142 of 500 files)\n",
            "Processing cl_cl02.txt (143 of 500 files)\n",
            "Processing cd_cd02.txt (144 of 500 files)\n",
            "Processing cf_cf45.txt (145 of 500 files)\n",
            "Processing ce_ce23.txt (146 of 500 files)\n",
            "Processing cb_cb03.txt (147 of 500 files)\n",
            "Processing cj_cj62.txt (148 of 500 files)\n",
            "Processing ca_ca03.txt (149 of 500 files)\n",
            "Processing cd_cd04.txt (150 of 500 files)\n",
            "Processing cg_cg07.txt (151 of 500 files)\n",
            "Processing cp_cp27.txt (152 of 500 files)\n",
            "Processing cl_cl19.txt (153 of 500 files)\n",
            "Processing ch_ch24.txt (154 of 500 files)\n",
            "Processing cg_cg34.txt (155 of 500 files)\n",
            "Processing ce_ce02.txt (156 of 500 files)\n",
            "Processing cj_cj53.txt (157 of 500 files)\n",
            "Processing cc_cc13.txt (158 of 500 files)\n",
            "Processing cj_cj60.txt (159 of 500 files)\n",
            "Processing cn_cn01.txt (160 of 500 files)\n",
            "Processing ca_ca04.txt (161 of 500 files)\n",
            "Processing cj_cj66.txt (162 of 500 files)\n",
            "Processing cf_cf04.txt (163 of 500 files)\n",
            "Processing cj_cj29.txt (164 of 500 files)\n",
            "Processing cj_cj01.txt (165 of 500 files)\n",
            "Processing cd_cd10.txt (166 of 500 files)\n",
            "Processing ca_ca29.txt (167 of 500 files)\n",
            "Processing cf_cf35.txt (168 of 500 files)\n",
            "Processing cg_cg09.txt (169 of 500 files)\n",
            "Processing cg_cg49.txt (170 of 500 files)\n",
            "Processing cn_cn24.txt (171 of 500 files)\n",
            "Processing ch_ch30.txt (172 of 500 files)\n",
            "Processing cg_cg60.txt (173 of 500 files)\n",
            "Processing cj_cj37.txt (174 of 500 files)\n",
            "Processing cr_cr09.txt (175 of 500 files)\n",
            "Processing cd_cd05.txt (176 of 500 files)\n",
            "Processing cj_cj74.txt (177 of 500 files)\n",
            "Processing cl_cl23.txt (178 of 500 files)\n",
            "Processing ce_ce14.txt (179 of 500 files)\n",
            "Processing cg_cg43.txt (180 of 500 files)\n",
            "Processing cg_cg67.txt (181 of 500 files)\n",
            "Processing ca_ca21.txt (182 of 500 files)\n",
            "Processing ca_ca26.txt (183 of 500 files)\n",
            "Processing cg_cg42.txt (184 of 500 files)\n",
            "Processing ce_ce35.txt (185 of 500 files)\n",
            "Processing cj_cj10.txt (186 of 500 files)\n",
            "Processing cg_cg71.txt (187 of 500 files)\n",
            "Processing cg_cg29.txt (188 of 500 files)\n",
            "Processing cn_cn20.txt (189 of 500 files)\n",
            "Processing cj_cj73.txt (190 of 500 files)\n",
            "Processing cf_cf41.txt (191 of 500 files)\n",
            "Processing cj_cj05.txt (192 of 500 files)\n",
            "Processing cg_cg12.txt (193 of 500 files)\n",
            "Processing cg_cg26.txt (194 of 500 files)\n",
            "Processing ck_ck04.txt (195 of 500 files)\n",
            "Processing ck_ck01.txt (196 of 500 files)\n",
            "Processing cg_cg02.txt (197 of 500 files)\n",
            "Processing cf_cf11.txt (198 of 500 files)\n",
            "Processing cf_cf32.txt (199 of 500 files)\n",
            "Processing cg_cg57.txt (200 of 500 files)\n",
            "Processing ch_ch14.txt (201 of 500 files)\n",
            "Processing cb_cb16.txt (202 of 500 files)\n",
            "Processing ca_ca14.txt (203 of 500 files)\n",
            "Processing cg_cg21.txt (204 of 500 files)\n",
            "Processing ce_ce04.txt (205 of 500 files)\n",
            "Processing cb_cb07.txt (206 of 500 files)\n",
            "Processing cb_cb19.txt (207 of 500 files)\n",
            "Processing cg_cg10.txt (208 of 500 files)\n",
            "Processing ch_ch05.txt (209 of 500 files)\n",
            "Processing cp_cp06.txt (210 of 500 files)\n",
            "Processing cf_cf33.txt (211 of 500 files)\n",
            "Processing cf_cf02.txt (212 of 500 files)\n",
            "Processing cn_cn27.txt (213 of 500 files)\n",
            "Processing cn_cn13.txt (214 of 500 files)\n",
            "Processing cl_cl12.txt (215 of 500 files)\n",
            "Processing cg_cg15.txt (216 of 500 files)\n",
            "Processing ch_ch26.txt (217 of 500 files)\n",
            "Processing cb_cb22.txt (218 of 500 files)\n",
            "Processing ch_ch11.txt (219 of 500 files)\n",
            "Processing cc_cc10.txt (220 of 500 files)\n",
            "Processing cj_cj72.txt (221 of 500 files)\n",
            "Processing ck_ck23.txt (222 of 500 files)\n",
            "Processing cp_cp18.txt (223 of 500 files)\n",
            "Processing cr_cr06.txt (224 of 500 files)\n",
            "Processing ce_ce16.txt (225 of 500 files)\n",
            "Processing ch_ch17.txt (226 of 500 files)\n",
            "Processing cg_cg47.txt (227 of 500 files)\n",
            "Processing cj_cj75.txt (228 of 500 files)\n",
            "Processing cj_cj11.txt (229 of 500 files)\n",
            "Processing ck_ck25.txt (230 of 500 files)\n",
            "Processing ca_ca24.txt (231 of 500 files)\n",
            "Processing cj_cj03.txt (232 of 500 files)\n",
            "Processing ca_ca41.txt (233 of 500 files)\n",
            "Processing cc_cc09.txt (234 of 500 files)\n",
            "Processing cb_cb20.txt (235 of 500 files)\n",
            "Processing ck_ck13.txt (236 of 500 files)\n",
            "Processing cd_cd17.txt (237 of 500 files)\n",
            "Processing cg_cg25.txt (238 of 500 files)\n",
            "Processing cn_cn04.txt (239 of 500 files)\n",
            "Processing cg_cg48.txt (240 of 500 files)\n",
            "Processing ck_ck14.txt (241 of 500 files)\n",
            "Processing cc_cc14.txt (242 of 500 files)\n",
            "Processing cf_cf48.txt (243 of 500 files)\n",
            "Processing ch_ch23.txt (244 of 500 files)\n",
            "Processing cp_cp23.txt (245 of 500 files)\n",
            "Processing cl_cl04.txt (246 of 500 files)\n",
            "Processing ca_ca10.txt (247 of 500 files)\n",
            "Processing cj_cj78.txt (248 of 500 files)\n",
            "Processing ck_ck21.txt (249 of 500 files)\n",
            "Processing ch_ch19.txt (250 of 500 files)\n",
            "Processing cf_cf26.txt (251 of 500 files)\n",
            "Processing cj_cj21.txt (252 of 500 files)\n",
            "Processing ce_ce36.txt (253 of 500 files)\n",
            "Processing ce_ce06.txt (254 of 500 files)\n",
            "Processing ck_ck12.txt (255 of 500 files)\n",
            "Processing ce_ce15.txt (256 of 500 files)\n",
            "Processing ch_ch01.txt (257 of 500 files)\n",
            "Processing ce_ce09.txt (258 of 500 files)\n",
            "Processing cr_cr03.txt (259 of 500 files)\n",
            "Processing cn_cn10.txt (260 of 500 files)\n",
            "Processing cn_cn18.txt (261 of 500 files)\n",
            "Processing ck_ck11.txt (262 of 500 files)\n",
            "Processing cj_cj08.txt (263 of 500 files)\n",
            "Processing cp_cp25.txt (264 of 500 files)\n",
            "Processing cm_cm04.txt (265 of 500 files)\n",
            "Processing ck_ck24.txt (266 of 500 files)\n",
            "Processing cl_cl17.txt (267 of 500 files)\n",
            "Processing cn_cn22.txt (268 of 500 files)\n",
            "Processing cl_cl14.txt (269 of 500 files)\n",
            "Processing cn_cn15.txt (270 of 500 files)\n",
            "Processing cl_cl08.txt (271 of 500 files)\n",
            "Processing ce_ce12.txt (272 of 500 files)\n",
            "Processing ca_ca20.txt (273 of 500 files)\n",
            "Processing cg_cg75.txt (274 of 500 files)\n",
            "Processing ca_ca43.txt (275 of 500 files)\n",
            "Processing cf_cf12.txt (276 of 500 files)\n",
            "Processing cj_cj24.txt (277 of 500 files)\n",
            "Processing cf_cf29.txt (278 of 500 files)\n",
            "Processing cj_cj69.txt (279 of 500 files)\n",
            "Processing ca_ca02.txt (280 of 500 files)\n",
            "Processing cf_cf27.txt (281 of 500 files)\n",
            "Processing cj_cj63.txt (282 of 500 files)\n",
            "Processing ce_ce20.txt (283 of 500 files)\n",
            "Processing cn_cn06.txt (284 of 500 files)\n",
            "Processing cn_cn05.txt (285 of 500 files)\n",
            "Processing ck_ck06.txt (286 of 500 files)\n",
            "Processing ca_ca36.txt (287 of 500 files)\n",
            "Processing ch_ch04.txt (288 of 500 files)\n",
            "Processing ch_ch15.txt (289 of 500 files)\n",
            "Processing cj_cj31.txt (290 of 500 files)\n",
            "Processing cg_cg61.txt (291 of 500 files)\n",
            "Processing cb_cb23.txt (292 of 500 files)\n",
            "Processing cg_cg74.txt (293 of 500 files)\n",
            "Processing cg_cg72.txt (294 of 500 files)\n",
            "Processing cg_cg11.txt (295 of 500 files)\n",
            "Processing cf_cf20.txt (296 of 500 files)\n",
            "Processing cj_cj50.txt (297 of 500 files)\n",
            "Processing cf_cf16.txt (298 of 500 files)\n",
            "Processing ch_ch25.txt (299 of 500 files)\n",
            "Processing cj_cj59.txt (300 of 500 files)\n",
            "Processing cl_cl11.txt (301 of 500 files)\n",
            "Processing cf_cf31.txt (302 of 500 files)\n",
            "Processing cj_cj13.txt (303 of 500 files)\n",
            "Processing cj_cj26.txt (304 of 500 files)\n",
            "Processing cp_cp29.txt (305 of 500 files)\n",
            "Processing cm_cm01.txt (306 of 500 files)\n",
            "Processing ce_ce22.txt (307 of 500 files)\n",
            "Processing cb_cb14.txt (308 of 500 files)\n",
            "Processing cj_cj06.txt (309 of 500 files)\n",
            "Processing cg_cg06.txt (310 of 500 files)\n",
            "Processing cg_cg59.txt (311 of 500 files)\n",
            "Processing cl_cl06.txt (312 of 500 files)\n",
            "Processing ca_ca31.txt (313 of 500 files)\n",
            "Processing cl_cl20.txt (314 of 500 files)\n",
            "Processing cj_cj36.txt (315 of 500 files)\n",
            "Processing cc_cc17.txt (316 of 500 files)\n",
            "Processing cp_cp11.txt (317 of 500 files)\n",
            "Processing ce_ce13.txt (318 of 500 files)\n",
            "Processing cp_cp08.txt (319 of 500 files)\n",
            "Processing cj_cj76.txt (320 of 500 files)\n",
            "Processing cp_cp28.txt (321 of 500 files)\n",
            "Processing cg_cg14.txt (322 of 500 files)\n",
            "Processing ce_ce26.txt (323 of 500 files)\n",
            "Processing cg_cg53.txt (324 of 500 files)\n",
            "Processing ce_ce05.txt (325 of 500 files)\n",
            "Processing cc_cc12.txt (326 of 500 files)\n",
            "Processing cj_cj23.txt (327 of 500 files)\n",
            "Processing cp_cp20.txt (328 of 500 files)\n",
            "Processing cn_cn21.txt (329 of 500 files)\n",
            "Processing cb_cb12.txt (330 of 500 files)\n",
            "Processing cp_cp07.txt (331 of 500 files)\n",
            "Processing ck_ck02.txt (332 of 500 files)\n",
            "Processing ck_ck10.txt (333 of 500 files)\n",
            "Processing cd_cd03.txt (334 of 500 files)\n",
            "Processing cb_cb18.txt (335 of 500 files)\n",
            "Processing ck_ck22.txt (336 of 500 files)\n",
            "Processing ca_ca15.txt (337 of 500 files)\n",
            "Processing cj_cj68.txt (338 of 500 files)\n",
            "Processing ck_ck20.txt (339 of 500 files)\n",
            "Processing cn_cn08.txt (340 of 500 files)\n",
            "Processing cj_cj64.txt (341 of 500 files)\n",
            "Processing cl_cl15.txt (342 of 500 files)\n",
            "Processing cj_cj09.txt (343 of 500 files)\n",
            "Processing cc_cc05.txt (344 of 500 files)\n",
            "Processing cn_cn19.txt (345 of 500 files)\n",
            "Processing ce_ce08.txt (346 of 500 files)\n",
            "Processing ca_ca33.txt (347 of 500 files)\n",
            "Processing cd_cd13.txt (348 of 500 files)\n",
            "Processing ce_ce31.txt (349 of 500 files)\n",
            "Processing ca_ca25.txt (350 of 500 files)\n",
            "Processing cp_cp03.txt (351 of 500 files)\n",
            "Processing cf_cf39.txt (352 of 500 files)\n",
            "Processing ce_ce27.txt (353 of 500 files)\n",
            "Processing cb_cb10.txt (354 of 500 files)\n",
            "Processing cg_cg44.txt (355 of 500 files)\n",
            "Processing ck_ck19.txt (356 of 500 files)\n",
            "Processing cg_cg51.txt (357 of 500 files)\n",
            "Processing cf_cf42.txt (358 of 500 files)\n",
            "Processing cl_cl01.txt (359 of 500 files)\n",
            "Processing cf_cf40.txt (360 of 500 files)\n",
            "Processing ca_ca08.txt (361 of 500 files)\n",
            "Processing cg_cg31.txt (362 of 500 files)\n",
            "Processing cf_cf19.txt (363 of 500 files)\n",
            "Processing ca_ca39.txt (364 of 500 files)\n",
            "Processing cg_cg16.txt (365 of 500 files)\n",
            "Processing cl_cl18.txt (366 of 500 files)\n",
            "Processing ch_ch08.txt (367 of 500 files)\n",
            "Processing cg_cg40.txt (368 of 500 files)\n",
            "Processing cj_cj65.txt (369 of 500 files)\n",
            "Processing cp_cp05.txt (370 of 500 files)\n",
            "Processing ch_ch07.txt (371 of 500 files)\n",
            "Processing ck_ck05.txt (372 of 500 files)\n",
            "Processing cb_cb15.txt (373 of 500 files)\n",
            "Processing cn_cn28.txt (374 of 500 files)\n",
            "Processing cj_cj48.txt (375 of 500 files)\n",
            "Processing cb_cb24.txt (376 of 500 files)\n",
            "Processing ca_ca32.txt (377 of 500 files)\n",
            "Processing cf_cf03.txt (378 of 500 files)\n",
            "Processing cj_cj15.txt (379 of 500 files)\n",
            "Processing ck_ck07.txt (380 of 500 files)\n",
            "Processing ca_ca37.txt (381 of 500 files)\n",
            "Processing cj_cj57.txt (382 of 500 files)\n",
            "Processing ch_ch18.txt (383 of 500 files)\n",
            "Processing cf_cf34.txt (384 of 500 files)\n",
            "Processing cp_cp14.txt (385 of 500 files)\n",
            "Processing cj_cj42.txt (386 of 500 files)\n",
            "Processing cf_cf13.txt (387 of 500 files)\n",
            "Processing cp_cp16.txt (388 of 500 files)\n",
            "Processing cn_cn29.txt (389 of 500 files)\n",
            "Processing cm_cm02.txt (390 of 500 files)\n",
            "Processing cc_cc16.txt (391 of 500 files)\n",
            "Processing ck_ck29.txt (392 of 500 files)\n",
            "Processing cp_cp24.txt (393 of 500 files)\n",
            "Processing cb_cb06.txt (394 of 500 files)\n",
            "Processing cg_cg64.txt (395 of 500 files)\n",
            "Processing ce_ce34.txt (396 of 500 files)\n",
            "Processing cf_cf25.txt (397 of 500 files)\n",
            "Processing cf_cf24.txt (398 of 500 files)\n",
            "Processing cb_cb25.txt (399 of 500 files)\n",
            "Processing cj_cj16.txt (400 of 500 files)\n",
            "Processing cj_cj40.txt (401 of 500 files)\n",
            "Processing ca_ca38.txt (402 of 500 files)\n",
            "Processing cg_cg22.txt (403 of 500 files)\n",
            "Processing cf_cf44.txt (404 of 500 files)\n",
            "Processing ce_ce07.txt (405 of 500 files)\n",
            "Processing cn_cn11.txt (406 of 500 files)\n",
            "Processing cj_cj25.txt (407 of 500 files)\n",
            "Processing ck_ck17.txt (408 of 500 files)\n",
            "Processing ck_ck15.txt (409 of 500 files)\n",
            "Processing ck_ck16.txt (410 of 500 files)\n",
            "Processing cg_cg50.txt (411 of 500 files)\n",
            "Processing cd_cd01.txt (412 of 500 files)\n",
            "Processing cg_cg66.txt (413 of 500 files)\n",
            "Processing ca_ca17.txt (414 of 500 files)\n",
            "Processing ca_ca35.txt (415 of 500 files)\n",
            "Processing cg_cg41.txt (416 of 500 files)\n",
            "Processing ck_ck18.txt (417 of 500 files)\n",
            "Processing cb_cb21.txt (418 of 500 files)\n",
            "Processing cg_cg63.txt (419 of 500 files)\n",
            "Processing cc_cc03.txt (420 of 500 files)\n",
            "Processing cb_cb27.txt (421 of 500 files)\n",
            "Processing cj_cj45.txt (422 of 500 files)\n",
            "Processing cn_cn23.txt (423 of 500 files)\n",
            "Processing cf_cf36.txt (424 of 500 files)\n",
            "Processing ca_ca28.txt (425 of 500 files)\n",
            "Processing cg_cg70.txt (426 of 500 files)\n",
            "Processing cb_cb04.txt (427 of 500 files)\n",
            "Processing ca_ca13.txt (428 of 500 files)\n",
            "Processing cj_cj07.txt (429 of 500 files)\n",
            "Processing cl_cl09.txt (430 of 500 files)\n",
            "Processing cc_cc15.txt (431 of 500 files)\n",
            "Processing cc_cc07.txt (432 of 500 files)\n",
            "Processing cd_cd14.txt (433 of 500 files)\n",
            "Processing cg_cg58.txt (434 of 500 files)\n",
            "Processing cj_cj04.txt (435 of 500 files)\n",
            "Processing ch_ch06.txt (436 of 500 files)\n",
            "Processing cf_cf07.txt (437 of 500 files)\n",
            "Processing cj_cj70.txt (438 of 500 files)\n",
            "Processing cd_cd06.txt (439 of 500 files)\n",
            "Processing cl_cl16.txt (440 of 500 files)\n",
            "Processing cf_cf22.txt (441 of 500 files)\n",
            "Processing cl_cl24.txt (442 of 500 files)\n",
            "Processing cb_cb02.txt (443 of 500 files)\n",
            "Processing cj_cj27.txt (444 of 500 files)\n",
            "Processing cl_cl22.txt (445 of 500 files)\n",
            "Processing ch_ch22.txt (446 of 500 files)\n",
            "Processing cg_cg20.txt (447 of 500 files)\n",
            "Processing cj_cj79.txt (448 of 500 files)\n",
            "Processing ch_ch16.txt (449 of 500 files)\n",
            "Processing ce_ce18.txt (450 of 500 files)\n",
            "Processing ce_ce03.txt (451 of 500 files)\n",
            "Processing cl_cl21.txt (452 of 500 files)\n",
            "Processing cd_cd16.txt (453 of 500 files)\n",
            "Processing ch_ch20.txt (454 of 500 files)\n",
            "Processing cg_cg30.txt (455 of 500 files)\n",
            "Processing cf_cf05.txt (456 of 500 files)\n",
            "Processing cr_cr08.txt (457 of 500 files)\n",
            "Processing cr_cr07.txt (458 of 500 files)\n",
            "Processing cc_cc04.txt (459 of 500 files)\n",
            "Processing ce_ce11.txt (460 of 500 files)\n",
            "Processing cr_cr01.txt (461 of 500 files)\n",
            "Processing cd_cd09.txt (462 of 500 files)\n",
            "Processing ca_ca01.txt (463 of 500 files)\n",
            "Processing ca_ca06.txt (464 of 500 files)\n",
            "Processing cg_cg13.txt (465 of 500 files)\n",
            "Processing ch_ch03.txt (466 of 500 files)\n",
            "Processing cg_cg69.txt (467 of 500 files)\n",
            "Processing cp_cp22.txt (468 of 500 files)\n",
            "Processing cd_cd07.txt (469 of 500 files)\n",
            "Processing cj_cj17.txt (470 of 500 files)\n",
            "Processing cp_cp01.txt (471 of 500 files)\n",
            "Processing cg_cg68.txt (472 of 500 files)\n",
            "Processing cj_cj14.txt (473 of 500 files)\n",
            "Processing cj_cj30.txt (474 of 500 files)\n",
            "Processing ca_ca19.txt (475 of 500 files)\n",
            "Processing cg_cg37.txt (476 of 500 files)\n",
            "Processing cj_cj41.txt (477 of 500 files)\n",
            "Processing ca_ca34.txt (478 of 500 files)\n",
            "Processing cj_cj71.txt (479 of 500 files)\n",
            "Processing ch_ch02.txt (480 of 500 files)\n",
            "Processing cj_cj44.txt (481 of 500 files)\n",
            "Processing cf_cf18.txt (482 of 500 files)\n",
            "Processing cp_cp21.txt (483 of 500 files)\n",
            "Processing cl_cl05.txt (484 of 500 files)\n",
            "Processing cj_cj58.txt (485 of 500 files)\n",
            "Processing cl_cl07.txt (486 of 500 files)\n",
            "Processing cm_cm05.txt (487 of 500 files)\n",
            "Processing cp_cp19.txt (488 of 500 files)\n",
            "Processing cc_cc06.txt (489 of 500 files)\n",
            "Processing cl_cl13.txt (490 of 500 files)\n",
            "Processing cg_cg62.txt (491 of 500 files)\n",
            "Processing ca_ca16.txt (492 of 500 files)\n",
            "Processing ca_ca40.txt (493 of 500 files)\n",
            "Processing cg_cg23.txt (494 of 500 files)\n",
            "Processing cp_cp09.txt (495 of 500 files)\n",
            "Processing cg_cg38.txt (496 of 500 files)\n",
            "Processing cj_cj35.txt (497 of 500 files)\n",
            "Processing cn_cn16.txt (498 of 500 files)\n",
            "Processing cm_cm06.txt (499 of 500 files)\n",
            "Processing ch_ch09.txt (500 of 500 files)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Давайте посмотрим действительно ли всё сработало, выведем самые частотные слова корпуса:"
      ],
      "metadata": {
        "id": "rCeCnEQbZaJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ct.head(brown_freq, hits = 5)  # Вывод 5 самых частотных слов"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmHAAxvsZRk6",
        "outputId": "e73b8196-11e2-40cd-83f3-8b5e8fc85c81"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the\t69836\n",
            "be\t37689\n",
            "of\t36365\n",
            "a\t30475\n",
            "and\t28826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Отлично, теперь постараемся разобраться с тем, что такое словарь и как извлечь из него ключи. Словарь это тип данных на python, который позволяет хранить пары ключ-значение, например:"
      ],
      "metadata": {
        "id": "KSE5GlVLZmjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Словарь иницилизируется с помощью фигурных скобок {}\n",
        "grammy_awards_dict = {\n",
        "    'Kanye West': 24,  # Внутри словаря мы пишем ключ, затем двоеточие,\n",
        "                       # а затем значение\n",
        "    'Jay-Z': 24,\n",
        "    'Beyoncé': 32\n",
        "}\n",
        "\n",
        "# Выведем словарь, чтобы посмотреть, что у нас получилось\n",
        "print(grammy_awards_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ahwlBqQZlVp",
        "outputId": "a36f4046-659a-4237-a09a-bb48036a4019"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Kanye West': 24, 'Jay-Z': 24, 'Beyoncé': 32}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Зная ключ словаря, мы можем найти значение. Для этого мы напишем ключ справа от переменной словаря:"
      ],
      "metadata": {
        "id": "7cn2pEiialSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Узнаем количество грэмми у Канье Веста\n",
        "print(grammy_awards_dict['Kanye West'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fv6KFOPnaj1r",
        "outputId": "15a8eed2-f2a1-4d74-8926-03b62bbb7192"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обратись к словарю частотности `brown_freq` и узнай частотность какого-нибудь английского слова:"
      ],
      "metadata": {
        "id": "GKJXYNy1a1pm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aUXGjVo5a1BJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(brown_freq['cat'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfQdoT2Za0Fl",
        "outputId": "77a132c9-fbe9-4dca-8f57-57854f948e71"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Также мы можем отдельно получить все ключи или значения словаря, или и те и другие:"
      ],
      "metadata": {
        "id": "ivnrmyc_bHF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(grammy_awards_dict.keys())  # Выведем все ключи"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQF4DvcIbF5o",
        "outputId": "780961e0-7c01-4f0a-c7ee-25e065c89cb0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['Kanye West', 'Jay-Z', 'Beyoncé'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(grammy_awards_dict.values())  # Выведем все значения"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIsRwr7qbT2D",
        "outputId": "7a75537c-af81-4b55-f6e6-e8fbf1369cac"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_values([24, 24, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(grammy_awards_dict.items())  # Выведем все пары ключ-значение"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctSW2TDtbWJU",
        "outputId": "91086ab4-7af7-44c1-dfc6-d56fdd7120e2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_items([('Kanye West', 24), ('Jay-Z', 24), ('Beyoncé', 32)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Отлично! Нас интересуют только ключи словаря частотности, но нам не подходит формат dict_keys (он указан в выводе ключей `grammy_awards_dict`). Сделаем из этого список и сохраним в отдельной переменной"
      ],
      "metadata": {
        "id": "_Qez31NGbeUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grammy_awards_keys = list(grammy_awards_dict.keys())\n",
        "\n",
        "print(grammy_awards_keys)  # Теперь у нас есть list, то есть список.\n",
        "                           # Со списком работать гораздо удобнее"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cO1mtbb9buYE",
        "outputId": "e3cd2d0a-15c2-4302-bf37-800db4b986ba"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Kanye West', 'Jay-Z', 'Beyoncé']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь сделай список ключей для словаря частотности `brown_freq`:"
      ],
      "metadata": {
        "id": "Cn-Lxp71b6GR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ijSeuCLjbzvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "brown_freq_keys = list(brown_freq.keys())\n",
        "\n",
        "# print(brown_freq_keys)  # Лучше это не выводить, их там много..."
      ],
      "metadata": {
        "id": "1wxO9M_TcRFn"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мы можем узнать, как много ключей в словаре, вызвав функцию\n",
        "`len()` и поместив в круглые скобки наш список ключей, напиши это ниже:"
      ],
      "metadata": {
        "id": "vzGkAFoRceEu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mrur5h2ycdmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(brown_freq_keys))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGaLMtMrcsyI",
        "outputId": "631a5b1f-60c5-4ebc-c9a4-9c9617da21c9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Отлично, у тебя прекрасно получается!"
      ],
      "metadata": {
        "id": "ajwFJ7g5cpnk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Сохранение списка слов в виде json массива\n",
        "Если мы каждый раз будем загружать весь корпус для того, чтобы извлечь список, у нас будет уходить на это несколько секунд. Кажется, что это немного, но кто станет ждать 5 секунд, чтобы увидеть свои опечатки? Мы воспользуемся одним из самых удобных форматов хранения данных — json.\n",
        "\n",
        "JSON (JavaScript Object Notation) — текстовый формат обмена данными. Бывают json объекты, массивы, строки, числа и литералы. Нас будет интересовать json массив, то есть просто список элементов. В качестве элементов будут наши слова.\n",
        "\n",
        "Но для начала разберёмся с тем, как на python работать с файлами. Всё, что нужно сейчас это простая конструкция ниже:"
      ],
      "metadata": {
        "id": "OHHkAiXHfyd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('Brown/ca_ca01.txt', 'r') as file:\n",
        "  print(file.read())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVFmEgDJiZAe",
        "outputId": "11bc4581-2066-4e5b-906a-363dc398ec55"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Fulton County Grand Jury said Friday an investigation of Atlanta 's recent primary election produced \" no evidence \" that any irregularities took place . \n",
            "The jury further said in term-end presentments that the City Executive Committee , which had over-all charge of the election , \" deserves the praise and thanks of the City of Atlanta \" for the manner in which the election was conducted . \n",
            "The September-October term jury had been charged by Fulton Superior Court Judge Durwood Pye to investigate reports of possible \" irregularities \" in the hard-fought primary which was won by Mayor-nominate Ivan Allen Jr .. \" Only a relative handful of such reports was received \" , the jury said , \" considering the widespread interest in the election , the number of voters and the size of this city \" . \n",
            "The jury said it did find that many of Georgia 's registration and election laws \" are outmoded or inadequate and often ambiguous \" . \n",
            "It recommended that Fulton legislators act \" to have these laws studied and revised to the end of modernizing and improving them \" . \n",
            "The grand jury commented on a number of other topics , among them the Atlanta and Fulton County purchasing departments which it said \" are well operated and follow generally accepted practices which inure to the best interest of both governments \" . \n",
            "Merger proposed However , the jury said it believes \" these two offices should be combined to achieve greater efficiency and reduce the cost of administration \" . \n",
            "The City Purchasing Department , the jury said , \" is lacking in experienced clerical personnel as a result of city personnel policies \" . \n",
            "It urged that the city \" take steps to remedy \" this problem . \n",
            "Implementation of Georgia 's automobile title law was also recommended by the outgoing jury . \n",
            "It urged that the next Legislature \" provide enabling funds and re-set the effective date so that an orderly implementation of the law may be effected \" . \n",
            "The grand jury took a swipe at the State Welfare Department 's handling of federal funds granted for child welfare services in foster homes . \n",
            "\" This is one of the major items in the Fulton County general assistance program \" , the jury said , but the State Welfare Department \" has seen fit to distribute these funds through the welfare departments of all counties in the state with the exception of Fulton County , which receives none of this money . \n",
            "The jurors said they realize \" a proportionate distribution of these funds might disable this program in our less populous counties \" . \n",
            "Nevertheless , \" we feel that in the future Fulton County should receive some portion of these available funds \" , the jurors said . \n",
            "\" Failure to do this will continue to place a disproportionate burden \" on Fulton taxpayers . \n",
            "The jury also commented on the Fulton ordinary 's court which has been under fire for its practices in the appointment of appraisers , guardians and administrators and the awarding of fees and compensation . \n",
            "Wards protected The jury said it found the court \" has incorporated into its operating procedures the recommendations \" of two previous grand juries , the Atlanta Bar Association and an interim citizens committee . \n",
            "\" These actions should serve to protect in fact and in effect the court 's wards from undue costs and its appointed and elected servants from unmeritorious criticisms \" , the jury said . \n",
            "Regarding Atlanta 's new multi-million-dollar airport , the jury recommended \" that when the new management takes charge Jan. 1 the airport be operated in a manner that will eliminate political influences \" . \n",
            "The jury did not elaborate , but it added that \" there should be periodic surveillance of the pricing practices of the concessionaires for the purpose of keeping the prices reasonable \" . \n",
            "Ask jail deputies On other matters , the jury recommended that : ( 1 ) Four additional deputies be employed at the Fulton County Jail and \" a doctor , medical intern or extern be employed for night and weekend duty at the jail \" . \n",
            "( 2 ) Fulton legislators \" work with city officials to pass enabling legislation that will permit the establishment of a fair and equitable \" pension plan for city employes . \n",
            "The jury praised the administration and operation of the Atlanta Police Department , the Fulton Tax Commissioner 's Office , the Bellwood and Alpharetta prison farms , Grady Hospital and the Fulton Health Department . \n",
            "Mayor William B. Hartsfield filed suit for divorce from his wife , Pearl Williams Hartsfield , in Fulton Superior Court Friday . \n",
            "His petition charged mental cruelty . \n",
            "The couple was married Aug. 2 , 1913 . \n",
            "They have a son , William Berry Jr. , and a daughter , Mrs. J.M. Cheshire of Griffin . \n",
            "Attorneys for the mayor said that an amicable property settlement has been agreed upon . \n",
            "The petition listed the mayor 's occupation as \" attorney \" and his age as 71 . \n",
            "It listed his wife 's age as 74 and place of birth as Opelika , Ala .. The petition said that the couple has not lived together as man and wife for more than a year . \n",
            "The Hartsfield home is at 637 E. Pelham Rd. A[fj] . \n",
            "Henry L. Bowden was listed on the petition as the mayor 's attorney . \n",
            "Hartsfield has been mayor of Atlanta , with exception of one brief interlude , since 1937 . \n",
            "His political career goes back to his election to city council in 1923 . \n",
            "The mayor 's present term of office expires Jan. 1 . \n",
            "He will be succeeded by Ivan Allen Jr. , who became a candidate in the Sept. 13 primary after Mayor Hartsfield announced that he would not run for reelection . \n",
            "Georgia Republicans are getting strong encouragement to enter a candidate in the 1962 governor 's race , a top official said Wednesday . \n",
            "Robert Snodgrass , state GOP chairman , said a meeting held Tuesday night in Blue Ridge brought enthusiastic responses from the audience . \n",
            "State Party Chairman James W. Dorsey added that enthusiasm was picking up for a state rally to be held Sept. 8 in Savannah at which newly elected Texas Sen. John Tower will be the featured speaker . \n",
            "In the Blue Ridge meeting , the audience was warned that entering a candidate for governor would force it to take petitions out into voting precincts to obtain the signatures of registered voters . \n",
            "Despite the warning , there was a unanimous vote to enter a candidate , according to Republicans who attended . \n",
            "When the crowd was asked whether it wanted to wait one more term to make the race , it voted no -- and there were no dissents . \n",
            "The largest hurdle the Republicans would have to face is a state law which says that before making a first race , one of two alternative courses must be taken : 1 Five per cent of the voters in each county must sign petitions requesting that the Republicans be allowed to place names of candidates on the general election ballot , or 2 The Republicans must hold a primary under the county unit system -- a system which the party opposes in its platform . \n",
            "Sam Caldwell , State Highway Department public relations director , resigned Tuesday to work for Lt. Gov. Garland Byrd 's campaign . \n",
            "Caldwell 's resignation had been expected for some time . \n",
            "He will be succeeded by Rob Ledford of Gainesville , who has been an assistant more than three years . \n",
            "When the gubernatorial campaign starts , Caldwell is expected to become a campaign coordinator for Byrd . \n",
            "The Georgia Legislature will wind up its 1961 session Monday and head for home -- where some of the highway bond money it approved will follow shortly . \n",
            "Before adjournment Monday afternoon , the Senate is expected to approve a study of the number of legislators allotted to rural and urban areas to determine what adjustments should be made . \n",
            "Gov. Vandiver is expected to make the traditional visit to both chambers as they work toward adjournment . \n",
            "Vandiver likely will mention the $ 100 million highway bond issue approved earlier in the session as his first priority item . \n",
            "Construction bonds Meanwhile , it was learned the State Highway Department is very near being ready to issue the first $ 30 million worth of highway reconstruction bonds . \n",
            "The bond issue will go to the state courts for a friendly test suit to test the validity of the act , and then the sales will begin and contracts let for repair work on some of Georgia 's most heavily traveled highways . \n",
            "A Highway Department source said there also is a plan there to issue some $ 3 million to $ 4 million worth of Rural Roads Authority bonds for rural road construction work . \n",
            "A revolving fund The department apparently intends to make the Rural Roads Authority a revolving fund under which new bonds would be issued every time a portion of the old ones are paid off by tax authorities . \n",
            "Vandiver opened his race for governor in 1958 with a battle in the Legislature against the issuance of $ 50 million worth of additional rural roads bonds proposed by then Gov. Marvin Griffin . \n",
            "The Highway Department source told The Constitution , however , that Vandiver has not been consulted yet about the plans to issue the new rural roads bonds . \n",
            "Schley County Rep. B.D. Pelham will offer a resolution Monday in the House to rescind the body 's action of Friday in voting itself a $ 10 per day increase in expense allowances . \n",
            "Pelham said Sunday night there was research being done on whether the \" quickie \" vote on the increase can be repealed outright or whether notice would have to first be given that reconsideration of the action would be sought . \n",
            "While emphasizing that technical details were not fully worked out , Pelham said his resolution would seek to set aside the privilege resolution which the House voted through 87-31 . \n",
            "A similar resolution passed in the Senate by a vote of 29-5 . \n",
            "As of Sunday night , there was no word of a resolution being offered there to rescind the action . \n",
            "Pelham pointed out that Georgia voters last November rejected a constitutional amendment to allow legislators to vote on pay raises for future Legislature sessions . \n",
            "A veteran Jackson County legislator will ask the Georgia House Monday to back federal aid to education , something it has consistently opposed in the past . \n",
            "Rep. Mac Barber of Commerce is asking the House in a privilege resolution to \" endorse increased federal support for public education , provided that such funds be received and expended \" as state funds . \n",
            "Barber , who is in his 13th year as a legislator , said there \" are some members of our congressional delegation in Washington who would like to see it ( the resolution ) passed \" . \n",
            "But he added that none of Georgia 's congressmen specifically asked him to offer the resolution . \n",
            "The resolution , which Barber tossed into the House hopper Friday , will be formally read Monday . \n",
            "It says that \" in the event Congress does provide this increase in federal funds \" , the State Board of Education should be directed to \" give priority \" to teacher pay raises . \n",
            "Colquitt -- After a long , hot controversy , Miller County has a new school superintendent , elected , as a policeman put it , in the \" coolest election I ever saw in this county \" . \n",
            "The new school superintendent is Harry Davis , a veteran agriculture teacher , who defeated Felix Bush , a school principal and chairman of the Miller County Democratic Executive Committee . \n",
            "Davis received 1,119 votes in Saturday 's election , and Bush got 402 . \n",
            "Ordinary Carey Williams , armed with a pistol , stood by at the polls to insure order . \n",
            "\" This was the coolest , calmest election I ever saw \" , Colquitt Policeman Tom Williams said . \n",
            "\" Being at the polls was just like being at church . \n",
            "I did n't smell a drop of liquor , and we did n't have a bit of trouble \" . \n",
            "The campaign leading to the election was not so quiet , however . \n",
            "It was marked by controversy , anonymous midnight phone calls and veiled threats of violence . \n",
            "The former county school superintendent , George P. Callan , shot himself to death March 18 , four days after he resigned his post in a dispute with the county school board . \n",
            "During the election campaign , both candidates , Davis and Bush , reportedly received anonymous telephone calls . \n",
            "Ordinary Williams said he , too , was subjected to anonymous calls soon after he scheduled the election . \n",
            "Many local citizens feared that there would be irregularities at the polls , and Williams got himself a permit to carry a gun and promised an orderly election . \n",
            "Sheriff Felix Tabb said the ordinary apparently made good his promise . \n",
            "\" Everything went real smooth \" , the sheriff said . \n",
            "\" There was n't a bit of trouble \" . \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мы открыли файл из корпуса, указав в аргументе функции open() путь к файлу в кавычках и способ взаимодействия: `'r'` это чтение (read), `'w'` это чтение и ввод (write). Если мы укажем `'w'` вместо `'r'`, то при отсутствии файла, он будет автоматически создан. Поменяй способ взаимодействия и запусти код. В files google colab должен появиться новый файл:"
      ],
      "metadata": {
        "id": "uVpoAYp0ik-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('new_file.json', 'r') as f:  # Поменяй r на w\n",
        "  pass  # pass значит отсутствие действия"
      ],
      "metadata": {
        "id": "1wOQUG2tjJIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('new_file.json', 'w') as f:  # Поменяй r на w\n",
        "  pass  # pass значит отсутствие действия"
      ],
      "metadata": {
        "id": "0L78tELgjR6y"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь импортируем библиотеку json и воспользуемся методом dump. В files google colab должен появиться массив после выполнения следующего кода:"
      ],
      "metadata": {
        "id": "ORik-dyxjdxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('words_massive.json', 'w') as f:\n",
        "  json.dump(brown_freq_keys, f)  # В качестве аргумента функции указываем то,\n",
        "                                 # что мы хотим сохранить, то есть список слов\n",
        "                                 # и то, куда мы хотим сохранить, то есть в\n",
        "                                 # созданный нам файл f"
      ],
      "metadata": {
        "id": "TqwFQny6jdEm"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вы можете открыть его двойным щелчком и посмотреть, что там действительно внутри все слова из нашего корпуса. Однако нам нужно будет использовать этот массив на python, а поэтому придётся загрузить json файл в переменную с помощью библиотеки. Для этого напиши простой код:\n",
        "\n",
        "1. Открой файл words_massive для чтения.\n",
        "3. Присвой переменной words_massive значение функции `json.load()`, указав в аргументе файл."
      ],
      "metadata": {
        "id": "y4AO2sWMkI71"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VsBLmz4qktQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('words_massive.json', 'r') as f:\n",
        "  words_massive = json.load(f)"
      ],
      "metadata": {
        "id": "nQCoUATPkt9N"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Запусти этот код, чтобы проверить сколько слов в нашем списке\n",
        "\n",
        "print(len(words_massive))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0CePb1Uk-8-",
        "outputId": "908c7d86-488c-4130-9a3e-91579e0e09ba"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Создание функции\n",
        "Только что ты создал в отдельных ячейках кода создание списка слов из корпуса. Но нам будет удобнее поместить это в функцию, которую мы сможем легко перемещать и использовать. Что такое функции и с чем их едят? Разберёмся на примере:"
      ],
      "metadata": {
        "id": "XvuLrCaJcIXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sum_numbers(a, b):\n",
        "  return a + b\n",
        "\n",
        "print(sum_numbers(5, 10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTusDaJhcOa_",
        "outputId": "b2c70149-6942-4ee8-e803-09762c67683d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вот наглядный пример функции, которая складывает 2 числа, которые передаются ей в качестве аргумента, то есть те числа, которые мы пишем внутри круглых скобок функции:\n",
        "\n",
        "```sum_numbers(5, 10)  # 5 и 10 это числа, они же аргумент функции```\n",
        "\n",
        "Напиши свою функцию, которая будет отнимать числа:"
      ],
      "metadata": {
        "id": "XO8Sl4d1dLQp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mq3SPYtQdKhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def difference_in_numbers(a, b):\n",
        "  return a - b\n",
        "\n",
        "print(difference_in_numbers(5, 10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuiuXsmddhgZ",
        "outputId": "5289dbfb-2167-44db-efb1-b6611bf0edea"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Скорее всего у тебя получилось повторить пример. Давай разберём, как ты это сделал:\n",
        "\n",
        "1. `def` это такое кодовое слово, с которого мы начинаем нашу функцию.\n",
        "2. После `def` идёт название функции. Оно может быть каким угодно, но лучше не повторять названий уже существующих функций, иначе можно натворить дел.\n",
        "3. После названия в круглых скобках указываем аргумент. Его может вовсе не быть, он может быть необязательным (значения указаны по умолчанию) или он может быть обязательным, как в нашем примере.\n",
        "4. Заканчивается всё двоеточием, после которого у нас начинается \"территория\" нашей функции, в которую входят строки, которые начинаются с нескольких пробелов от начала и заканчивается теми строками, которые находятся на уровне def:\n",
        "```\n",
        "def blah_blah():\n",
        "      # территория функции\n",
        "      # территория функции\n",
        "      # территория функции\n",
        "# территория вне функции\n",
        "```\n",
        "5. В \"теле\" функции мы определяем действия, которые будет совершать функция при вызове. В нашем примере это return, то есть мы получим обратно какое-то значение, в нашем случае разность двух чисел.\n",
        "\n",
        "Чтобы проверить, как ты усвоил информацию, создай функцию\n",
        "`get_words_massive()`, которая будет открывать файл words_massive.json и читать массив слов в переменную. Переменную нужно будет вернуть с помощью return"
      ],
      "metadata": {
        "id": "FWusfL2fdwUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_words_massive():\n",
        "  # Открой words_massive.json и с помощью json загрузи массив в переменную\n",
        "\n",
        "\n",
        "  # Верни переменную с помощью return"
      ],
      "metadata": {
        "id": "1E0l4O4Kfllx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_words_massive():\n",
        "  # Открой words_massive.json и с помощью json загрузи массив в переменную\n",
        "  with open('words_massive.json', 'r') as f:\n",
        "    words = json.load(f)\n",
        "\n",
        "  # Верни переменную с помощью return\n",
        "  return words"
      ],
      "metadata": {
        "id": "K_O5x_LCmLJ3"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Запусти этот код, чтобы проверить сколько слов в нашем массиве\n",
        "print(len(get_words_massive()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaxXwZbgmTqz",
        "outputId": "ab251179-d876-482c-9271-feaf8d202998"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Поздравляю, ты отлично справился/справилась :)\n",
        "Теперь, пожалуйста, скачай файл words_massive.json в корневую папку проекта, нажав по нему левой кнопкой мыши, а затем \"скачать\"/\"download\""
      ],
      "metadata": {
        "id": "ldBXitKVmgwX"
      }
    }
  ]
}